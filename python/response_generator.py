import os
import random
import openai
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
USE_MOCK = os.getenv("USE_MOCK", "false").lower() == "true"

# ëŒ€í™” ì´ë ¥
conversation_history = []
last_indices = {}

# ì‹œê°„/ì¹´í…Œê³ ë¦¬ í•„í„°
EXCLUDE_CATEGORY_BY_TIME = {
    "ì ì‹¬": ["ì¹´í˜", "ë””ì €íŠ¸", "í¬ì¥ë§ˆì°¨", "ë§¥ì£¼", "ìš”ë¦¬ì£¼ì ", "ë¯¼ì†ì£¼ì ", "ë² ì´ì»¤ë¦¬", "ì¼€ì´í¬ì „ë¬¸", "ì´ìì¹´ì•¼", "ì»¤í”¼", "ìˆ ì§‘"],
    "ì €ë…": ["ì¹´í˜", "ë””ì €íŠ¸", "í¬ì¥ë§ˆì°¨", "ë§¥ì£¼", "ìš”ë¦¬ì£¼ì ", "ë¯¼ì†ì£¼ì ", "ë² ì´ì»¤ë¦¬", "ì¼€ì´í¬ì „ë¬¸", "ì´ìì¹´ì•¼", "ì»¤í”¼", "ìˆ ì§‘"],
    "ì•¼ì‹": ["ì¹´í˜", "ë””ì €íŠ¸", "ì»¤í”¼", "ë² ì´ì»¤ë¦¬", "ì¼€ì´í¬ì „ë¬¸", "ê¹€ë°¥", "ë„ì‹œë½", "ì¢…í•©ë¶„ì‹", "ì•„ê·€ì°œ,í•´ë¬¼ì°œ"]
}

EXCLUDE_CATEGORY_BY_CATEGORY = {
    "ì¹´í˜": ["í•œì‹", "ë¶„ì‹", "ì¤‘ì‹", "ì¼ì‹", "ì–‘ì‹", "ì¹˜í‚¨", "íŒ¨ìŠ¤íŠ¸í‘¸ë“œ", "êµ­ë°¥", "ê³ ê¸°", "ìˆ ì§‘"],
    "ë””ì €íŠ¸": ["í•œì‹", "ì¤‘ì‹", "ë¶„ì‹", "ì¹˜í‚¨"],
    "ìˆ ì§‘": ["ì¹´í˜", "ë””ì €íŠ¸", "ì»¤í”¼", "ë² ì´ì»¤ë¦¬", "ì¼€ì´í¬ì „ë¬¸"]
}


def apply_category_filters(restaurant_list, parsed_query):
    exclude = set()
    time = parsed_query.get("time")
    category = parsed_query.get("category")

    if time in EXCLUDE_CATEGORY_BY_TIME:
        exclude.update(EXCLUDE_CATEGORY_BY_TIME[time])
    if category in EXCLUDE_CATEGORY_BY_CATEGORY:
        exclude.update(EXCLUDE_CATEGORY_BY_CATEGORY[category])

    if exclude:
        return [r for r in restaurant_list if all(x not in r.get("category", "") for x in exclude)]
    return restaurant_list

# ìˆœí™˜ì‹ ìƒ˜í”Œë§
def rotate_sample(results: list, k: int = 3, tag: str = ""):
    n = len(results)
    if n == 0:
        return []
    start = last_indices.get(tag, 0) % n
    sampled = [results[(start + i) % n] for i in range(min(k, n))]
    last_indices[tag] = (start + k) % n
    return sampled


def generate_mock_response(user_query, restaurant_results, parsed_query):
    print(f"â–¶ ì§ˆë¬¸: {user_query}")
    base_list = list(restaurant_results)
    print("ğŸ” DBì—ì„œ ë„˜ì–´ì˜¨ ì›ë³¸:", [r["name"] for r in base_list])

    if parsed_query:
        base_list = apply_category_filters(base_list, parsed_query)
        print("ğŸ§¹ í•„í„°ë§ ê²°ê³¼:", [r["name"] for r in base_list])

    scored_list = []
    for r in base_list:
        score = r.get("like_count", 0) + random.uniform(0, 20)
        r["recommend_score"] = score
        scored_list.append(r)

    scored_list.sort(key=lambda r: r["recommend_score"], reverse=True)

    print("â¤ï¸ ì¶”ì²œ í›„ë³´ ì ìˆ˜:")
    for r in scored_list[:10]:
        print(f"  - {r['name']:20} | ì¢‹ì•„ìš”: {r['like_count']:>4} | ì ìˆ˜: {r['recommend_score']:.2f}")

    sample = scored_list[:2]
    print("âœ… ìµœì¢… ì¶”ì²œ 2ê³³:", [r["name"] for r in sample])

    if not sample:
        return f"[MOCK] '{user_query}' â†’ ì¶”ì²œí•  ìŒì‹ì ì´ ì—†ìŠµë‹ˆë‹¤."
    lines = "\n".join(f"- {r['name']} (ì£¼ì†Œ: {r['address']})" for r in sample)
    return f"[MOCK] '{user_query}' â†’ ë‹¤ìŒ ì‹ë‹¹ì„ ì¶”ì²œí•©ë‹ˆë‹¤:\n{lines}"


def generate_response(user_query: str, restaurant_results: list, weather_info: dict, parsed_query: dict = None) -> str:
    if USE_MOCK:
        return generate_mock_response(user_query, restaurant_results, parsed_query)

    system_msg = {
        "role": "system",
        "content": (
            "ë‹¹ì‹ ì€ ì§„ì£¼ ê²½ìƒëŒ€í•™êµ ì£¼ë³€(ê°€ì¢Œë™Â·ì¹ ì•”ë™) ë§›ì§‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
            "ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬ë¡œ, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë§ì¶° ìµœëŒ€ 3ê³³ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”."
        )
    }

    few_shot = [
        {"role": "user", "content": "ì €ë…ì— ë­ ë¨¹ì„ê¹Œ?"},
        {"role": "assistant", "content": "ì €ë…ìœ¼ë¡œëŠ” [ë³¸ë„ì‹œë½ ê°€ì¢Œì ]ì„ ì¶”ì²œë“œë ¤ìš”. "}
    ]

    weather_text = (
        f"í˜„ì¬ ê¸°ì˜¨ì€ {weather_info['temperature']}Â°Cì´ê³ , {weather_info['recommendation']}\n"
        if weather_info and weather_info.get("temperature") is not None else
        "í˜„ì¬ ë‚ ì”¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
    )

    sampled = []
    if restaurant_results:
        base_list = list(restaurant_results)
        print("ğŸ” DBì—ì„œ ë„˜ì–´ì˜¨ ì›ë³¸:", [r["name"] for r in base_list])
        scored_list = []
        for r in base_list:
            score = r.get("like_count", 0) + random.uniform(0, 20)
            r["recommend_score"] = score
            scored_list.append(r)
        scored_list.sort(key=lambda r: r["recommend_score"], reverse=True)
        print("â¤ï¸ ì¶”ì²œ í›„ë³´ ì ìˆ˜:")
        for r in scored_list[:10]:
            print(f"  - {r['name']:20} | ì¢‹ì•„ìš”: {r['like_count']:>4} | ì ìˆ˜: {r['recommend_score']:.2f}")
        sampled = scored_list[:2]

    resto_text = (
        "ì¶”ì²œ ìŒì‹ì  (2ê³³):\n" +
        "\n".join(f"- {r['name']} (ì£¼ì†Œ: {r['address']})" for r in sampled) + #, íŠ¹ì§•: {r['info']}
        "\n"
        if sampled else
        "ì¶”ì²œí•  ìŒì‹ì ì´ ì—†ìŠµë‹ˆë‹¤.\n"
    )

    user_msg = {
        "role": "user",
        "content": (
            f"ì§ˆë¬¸: {user_query}\n"
            f"{weather_text}"
            f"{resto_text}"
            "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ì²œ ë¬¸ì¥ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."
        )
    }

    conversation_history.append(user_msg)
    if len(conversation_history) > 2:
        conversation_history.pop(0)

    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[system_msg] + few_shot + conversation_history,
        temperature=0.75,
        top_p=0.95,
        max_tokens=200,
    )

    answer = response.choices[0].message.content.strip()
    conversation_history.append({"role": "assistant", "content": answer})
    return answer

print(f"âœ… í˜„ì¬ ì ìš©ëœ í‚¤: {openai.api_key}")
